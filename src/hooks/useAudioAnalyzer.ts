import { useState, useRef, useCallback } from 'react'
import Pitchfinder from 'pitchfinder'
import useAudioSettings from './useAudioSettings'
import { PitchValidator, MedianFilter, findFundamental } from '../utils/advancedPitchDetection'

interface AudioAnalyzerState {
  frequency: number | null
  isAnalyzing: boolean
  error: string | null
}

const useAudioAnalyzer = () => {
  const [state, setState] = useState<AudioAnalyzerState>({
    frequency: null,
    isAnalyzing: false,
    error: null
  })

  const { settings, getMediaConstraints, getAnalyserConfig } = useAudioSettings()

  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const pitchDetectorRef = useRef<any>(null)

  const startAnalysis = useCallback(async () => {
    try {
      // R√©initialiser l'√©tat
      setState(prev => ({ ...prev, error: null, isAnalyzing: false }))

      // Demander l'acc√®s au microphone avec les param√®tres configur√©s
      const mediaConstraints = getMediaConstraints()
      const stream = await navigator.mediaDevices.getUserMedia(mediaConstraints)

      mediaStreamRef.current = stream

      // Cr√©er le contexte audio
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
      const audioContext = audioContextRef.current

      // Cr√©er l'analyseur
      analyserRef.current = audioContext.createAnalyser()
      const analyser = analyserRef.current

      // Configuration de l'analyseur avec les param√®tres utilisateur
      const analyserConfig = getAnalyserConfig()
      analyser.fftSize = analyserConfig.fftSize
      analyser.smoothingTimeConstant = analyserConfig.smoothingTimeConstant
      analyser.minDecibels = analyserConfig.minDecibels
      analyser.maxDecibels = analyserConfig.maxDecibels

      // Connecter le microphone √† l'analyseur
      const source = audioContext.createMediaStreamSource(stream)
      source.connect(analyser)

      // Initialiser le d√©tecteur de pitch avec YIN optimis√© pour guitare
      pitchDetectorRef.current = Pitchfinder.YIN({
        sampleRate: audioContext.sampleRate,
        threshold: settings.threshold, // Seuil de confiance configurable
        probabilityThreshold: 0.1, // Plus permissif pour d√©tecter les notes faibles
        bufferSize: 2048 // Taille de buffer pour meilleure pr√©cision basses fr√©quences
      })

      // Buffer pour les donn√©es audio - Version am√©lior√©e
      const bufferLength = analyser.frequencyBinCount
      const dataArray = new Float32Array(bufferLength)

      // Variables pour la calibration du bruit
      let frameCount = 0
      let noiseCalibrationFrames = 0
      let noiseSum = 0
      let baselineNoise = 0

      // Filtres avanc√©s comme GuitarTuna
      const medianFilter = new MedianFilter(7) // M√©diane sur 7 mesures
      const pitchValidator = new PitchValidator()

      // D√©tecteur de signal r√©el (pas de bruit constant)
      let previousFrequency: number | null = null
      let constantFrequencyCount = 0
      const CONSTANT_THRESHOLD = 5 // Si m√™me fr√©quence 5 fois = bruit
      let ignoreUntilFrame = 0 // Ignorer les d√©tections pendant X frames apr√®s un bruit constant

      setState(prev => ({ ...prev, isAnalyzing: true }))

      // Fonction d'analyse en temps r√©el am√©lior√©e
      const analyze = () => {
        if (!analyser || !pitchDetectorRef.current) return

        try {
          // Obtenir les donn√©es audio temporelles pour calibration (m√™me m√©thode que le test)
          const timeDomainData = new Uint8Array(analyser.fftSize)
          analyser.getByteTimeDomainData(timeDomainData)

          // Calculer le niveau RMS pour v√©rifier le signal (m√™me calcul que le test)
          let rms = 0
          for (let i = 0; i < timeDomainData.length; i++) {
            const sample = (timeDomainData[i] - 128) / 128 // Normaliser -1 √† 1
            rms += sample * sample
          }
          rms = Math.sqrt(rms / timeDomainData.length)

          // Calibration du bruit de fond (60 premi√®res frames)
          if (noiseCalibrationFrames < 60) {
            noiseSum += rms
            noiseCalibrationFrames++
            if (noiseCalibrationFrames === 60) {
              baselineNoise = noiseSum / 60
              console.log(`üé∏ Accordeur - Bruit de fond calibr√©: ${(baselineNoise * 100).toFixed(1)}%`)
            }
          }

          // Mode guitare acoustique : utiliser le signal brut sans soustraction de bruit
          const rawSignalStrength = rms * 100 * 20 // Amplifier x20 le signal brut
          const cleanRms = Math.max(0, rms - baselineNoise)
          const cleanSignalStrength = cleanRms * 100

          // Utiliser le signal le plus fort des deux
          const signalStrength = Math.max(rawSignalStrength, cleanSignalStrength)

          frameCount++
          if (frameCount % 60 === 0) {
            console.log(`üé∏ Signal guitare: ${signalStrength.toFixed(1)}% (RMS brut: ${(rms * 100).toFixed(1)}%, Bruit: ${(baselineNoise * 100).toFixed(1)}%)`)
          }

          // V√©rifier si on doit ignorer les d√©tections (apr√®s d√©tection de bruit constant)
          if (frameCount < ignoreUntilFrame) {
            setState(prev => ({ ...prev, frequency: null }))
            if (frameCount % 60 === 0) {
              const remainingFrames = ignoreUntilFrame - frameCount
              console.log(`‚è≥ Pause anti-bruit: encore ${Math.ceil(remainingFrames / 60)} secondes...`)
            }
            return
          }

          // Seulement analyser si le signal est d√©tectable (mode guitare acoustique)
          if (signalStrength > 8) { // Seuil adapt√© √† ton micro/guitare
            // Message de reprise apr√®s une pause anti-bruit
            if (frameCount === ignoreUntilFrame && ignoreUntilFrame > 0) {
              console.log(`‚úÖ ACCORDEUR R√âACTIV√â - Pr√™t √† d√©tecter les notes !`)
            }
            console.log(`üé∏ SIGNAL FORT d√©tect√©: ${signalStrength.toFixed(1)}% - Analyse en cours...`)

            // Convertir les donn√©es Uint8 en Float32 pour Pitchfinder
            const floatData = new Float32Array(timeDomainData.length)
            for (let i = 0; i < timeDomainData.length; i++) {
              floatData[i] = (timeDomainData[i] - 128) / 128 // Normaliser -1 √† 1
            }

            // D√©tecter la fr√©quence avec Pitchfinder
            let rawFrequency = pitchDetectorRef.current(floatData)

            console.log(`üîç Pitchfinder r√©sultat: ${rawFrequency ? rawFrequency.toFixed(1) + ' Hz' : 'null'}`)

            if (rawFrequency && rawFrequency > 0) {
              // Trouver la vraie fondamentale avec l'algorithme avanc√©
              const frequency = findFundamental(rawFrequency)
              console.log(`üéØ Apr√®s findFundamental: ${frequency.toFixed(1)} Hz`)

              // Validation avec d√©tection de bruit constant
              if (frequency >= 70 && frequency <= 400) {
                // V√©rifier si c'est une fr√©quence constante (bruit √©lectronique)
                const roundedFreq = Math.round(frequency * 10) / 10 // Arrondir √† 0.1 Hz

                if (previousFrequency !== null && Math.abs(roundedFreq - previousFrequency) < 0.5) {
                  constantFrequencyCount++
                  if (constantFrequencyCount >= CONSTANT_THRESHOLD) {
                    console.log(`üö´ BRUIT CONSTANT d√©tect√©: ${frequency.toFixed(1)} Hz (${constantFrequencyCount} fois) - PAUSE 2 secondes`)
                    setState(prev => ({ ...prev, frequency: null }))
                    // Ignorer les d√©tections pendant 120 frames (2 secondes) pour laisser le bruit se calmer
                    ignoreUntilFrame = frameCount + 120
                    constantFrequencyCount = 0
                    previousFrequency = null
                    return
                  }
                } else {
                  constantFrequencyCount = 0 // R√©initialiser si fr√©quence change
                }

                previousFrequency = roundedFreq

                // Si c'est une vraie variation, accepter la note
                if (constantFrequencyCount < CONSTANT_THRESHOLD) {
                  console.log(`üéµ VRAIE NOTE: ${frequency.toFixed(1)} Hz (signal: ${signalStrength.toFixed(1)}%, variation: ${constantFrequencyCount})`)
                  setState(prev => ({
                    ...prev,
                    frequency: Math.round(frequency * 100) / 100
                  }))
                }
              } else {
                console.log(`‚ùå Fr√©quence hors gamme: ${frequency.toFixed(1)} Hz`)
              }
            } else {
              console.log(`‚ùå Pitchfinder n'a rien d√©tect√© (signal: ${signalStrength.toFixed(1)}%)`)
            }
          } else {
            // Signal trop faible, r√©initialiser
            setState(prev => ({ ...prev, frequency: null }))
            if (frameCount % 120 === 0 && signalStrength > 1) {
              console.log(`üí§ Signal trop faible: ${signalStrength.toFixed(1)}% (besoin > 8%)`)
              console.log(`üí° Conseil: Joue plus fort pr√®s du microphone !`)
            }
          }

        } catch (error) {
          console.error('Erreur analyse accordeur:', error)
        }

        // Continuer l'analyse
        animationFrameRef.current = requestAnimationFrame(analyze)
      }

      // D√©marrer l'analyse
      console.log('üé∏ D√©marrage de l\'accordeur...')
      analyze()

    } catch (error) {
      console.error('Erreur lors de l\'initialisation de l\'audio:', error)
      let errorMessage = 'Erreur inconnue'

      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = 'Acc√®s au microphone refus√©. Veuillez autoriser l\'acc√®s dans les param√®tres de votre navigateur.'
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'Aucun microphone d√©tect√©. Veuillez connecter un microphone.'
        } else if (error.name === 'NotSupportedError') {
          errorMessage = 'Votre navigateur ne supporte pas cette fonctionnalit√©.'
        } else {
          errorMessage = error.message
        }
      }

      setState(prev => ({
        ...prev,
        error: errorMessage,
        isAnalyzing: false,
        frequency: null
      }))
    }
  }, [getMediaConstraints, getAnalyserConfig, settings.threshold, settings.sensitivity])

  const stopAnalysis = useCallback(() => {
    // Arr√™ter l'animation
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
      animationFrameRef.current = null
    }

    // Fermer le stream m√©dia
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop())
      mediaStreamRef.current = null
    }

    // Fermer le contexte audio
    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }

    // R√©initialiser les r√©f√©rences
    analyserRef.current = null
    pitchDetectorRef.current = null

    // Mettre √† jour l'√©tat
    setState({
      frequency: null,
      isAnalyzing: false,
      error: null
    })
  }, [])

  // Nettoyage automatique lors du d√©montage du composant
  const cleanup = useCallback(() => {
    stopAnalysis()
  }, [stopAnalysis])

  return {
    frequency: state.frequency,
    isAnalyzing: state.isAnalyzing,
    error: state.error,
    startAnalysis,
    stopAnalysis,
    cleanup
  }
}

export default useAudioAnalyzer
